{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data imports\n",
    "\n",
    "We import Pandas, numpy and scipy for data structuresWe use gensim for LDA, and sklearn for NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "import scipy as sp;\n",
    "import sklearn;\n",
    "import sys;\n",
    "from nltk.corpus import stopwords;\n",
    "import nltk;\n",
    "from gensim.models import ldamodel\n",
    "import gensim.corpora;\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer;\n",
    "from sklearn.decomposition import NMF;\n",
    "from sklearn.preprocessing import normalize;\n",
    "import pickle;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data\n",
    "\n",
    "We are using the ABC News headlines dataset. Some lines are badly formatted (very few), so we are skipping those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/abcnews-date-text.csv', error_bad_lines=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We only need the Headlines_text column from the data\n",
    "data_text = data[['headline_text']];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to remove stopwords first. Casting all values to float will make it easier to iterate over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_text = data_text.astype('str');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx in range(len(data_text)):\n",
    "    \n",
    "    #go through each word in each data_text row, remove stopwords, and set them on the index.\n",
    "    data_text.iloc[idx]['headline_text'] = [word for word in data_text.iloc[idx]['headline_text'].split(' ') if word not in stopwords.words()];\n",
    "    \n",
    "    #print logs to monitor output\n",
    "    if idx % 1000 == 0:\n",
    "        sys.stdout.write('\\rc = ' + str(idx) + ' / ' + str(len(data_text)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save data because it takes very long to remove stop words\n",
    "pickle.dump(data_text, open('data_text.dat', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the words as an array for lda input\n",
    "train_headlines = [value[0] for value in data_text.iloc[0:].values];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#number of topics we will cluster for: 10\n",
    "num_topics = 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA\n",
    "\n",
    "We will use the gensim library for LDA. First, we obtain a id-2-word dictionary. For each headline, we will use the dictionary to obtain a mapping of the word id to their word counts. The LDA model uses both of these mappings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id2word = gensim.corpora.Dictionary(train_headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = [id2word.doc2bow(text) for text in train_headlines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda = ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics=num_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generating LDA topics\n",
    "\n",
    "We will iterate over the number of topics, get the top words in each cluster and add them to a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lda_topics(model, num_topics):\n",
    "    word_dict = {};\n",
    "    for i in range(num_topics):\n",
    "        words = model.show_topic(i, topn = 20);\n",
    "        word_dict['Topic # ' + '{:02d}'.format(i+1)] = [i[0] for i in words];\n",
    "    return pd.DataFrame(word_dict);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic # 01</th>\n",
       "      <th>Topic # 02</th>\n",
       "      <th>Topic # 03</th>\n",
       "      <th>Topic # 04</th>\n",
       "      <th>Topic # 05</th>\n",
       "      <th>Topic # 06</th>\n",
       "      <th>Topic # 07</th>\n",
       "      <th>Topic # 08</th>\n",
       "      <th>Topic # 09</th>\n",
       "      <th>Topic # 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>queensland</td>\n",
       "      <td>rural</td>\n",
       "      <td>sydney</td>\n",
       "      <td>canberra</td>\n",
       "      <td>wa</td>\n",
       "      <td>police</td>\n",
       "      <td>australian</td>\n",
       "      <td>government</td>\n",
       "      <td>south</td>\n",
       "      <td>trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>court</td>\n",
       "      <td>two</td>\n",
       "      <td>world</td>\n",
       "      <td>north</td>\n",
       "      <td>calls</td>\n",
       "      <td>death</td>\n",
       "      <td>australia</td>\n",
       "      <td>says</td>\n",
       "      <td>election</td>\n",
       "      <td>adelaide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>woman</td>\n",
       "      <td>90</td>\n",
       "      <td>china</td>\n",
       "      <td>perth</td>\n",
       "      <td>new</td>\n",
       "      <td>say</td>\n",
       "      <td>day</td>\n",
       "      <td>found</td>\n",
       "      <td>news</td>\n",
       "      <td>seconds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nsw</td>\n",
       "      <td>attack</td>\n",
       "      <td>win</td>\n",
       "      <td>coast</td>\n",
       "      <td>call</td>\n",
       "      <td>missing</td>\n",
       "      <td>country</td>\n",
       "      <td>donald</td>\n",
       "      <td>tasmania</td>\n",
       "      <td>years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indigenous</td>\n",
       "      <td>crash</td>\n",
       "      <td>cup</td>\n",
       "      <td>2015</td>\n",
       "      <td>labor</td>\n",
       "      <td>children</td>\n",
       "      <td>one</td>\n",
       "      <td>accused</td>\n",
       "      <td>says</td>\n",
       "      <td>national</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>charged</td>\n",
       "      <td>car</td>\n",
       "      <td>business</td>\n",
       "      <td>afl</td>\n",
       "      <td>funding</td>\n",
       "      <td>nrl</td>\n",
       "      <td>hour</td>\n",
       "      <td>us</td>\n",
       "      <td>water</td>\n",
       "      <td>family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>child</td>\n",
       "      <td>police</td>\n",
       "      <td>market</td>\n",
       "      <td>gold</td>\n",
       "      <td>nt</td>\n",
       "      <td>darwin</td>\n",
       "      <td>tasmanian</td>\n",
       "      <td>people</td>\n",
       "      <td>victoria</td>\n",
       "      <td>drug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>power</td>\n",
       "      <td>women</td>\n",
       "      <td>australia</td>\n",
       "      <td>record</td>\n",
       "      <td>council</td>\n",
       "      <td>john</td>\n",
       "      <td>test</td>\n",
       "      <td>trial</td>\n",
       "      <td>top</td>\n",
       "      <td>near</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>farmers</td>\n",
       "      <td>dead</td>\n",
       "      <td>final</td>\n",
       "      <td>four</td>\n",
       "      <td>hobart</td>\n",
       "      <td>west</td>\n",
       "      <td>year</td>\n",
       "      <td>new</td>\n",
       "      <td>take</td>\n",
       "      <td>hospital</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>murder</td>\n",
       "      <td>health</td>\n",
       "      <td>home</td>\n",
       "      <td>interview</td>\n",
       "      <td>qld</td>\n",
       "      <td>cattle</td>\n",
       "      <td>budget</td>\n",
       "      <td>guilty</td>\n",
       "      <td>life</td>\n",
       "      <td>park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>live</td>\n",
       "      <td>christmas</td>\n",
       "      <td>league</td>\n",
       "      <td>show</td>\n",
       "      <td>royal</td>\n",
       "      <td>road</td>\n",
       "      <td>says</td>\n",
       "      <td>png</td>\n",
       "      <td>residents</td>\n",
       "      <td>energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>police</td>\n",
       "      <td>killed</td>\n",
       "      <td>melbourne</td>\n",
       "      <td>cyclone</td>\n",
       "      <td>support</td>\n",
       "      <td>search</td>\n",
       "      <td>change</td>\n",
       "      <td>ahead</td>\n",
       "      <td>northern</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sex</td>\n",
       "      <td>nsw</td>\n",
       "      <td>hit</td>\n",
       "      <td>2016</td>\n",
       "      <td>bill</td>\n",
       "      <td>coal</td>\n",
       "      <td>new</td>\n",
       "      <td>markets</td>\n",
       "      <td></td>\n",
       "      <td>court</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>school</td>\n",
       "      <td>house</td>\n",
       "      <td>turnbull</td>\n",
       "      <td>year</td>\n",
       "      <td>aboriginal</td>\n",
       "      <td>river</td>\n",
       "      <td>violence</td>\n",
       "      <td>week</td>\n",
       "      <td>hill</td>\n",
       "      <td>million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>federal</td>\n",
       "      <td>second</td>\n",
       "      <td>first</td>\n",
       "      <td>president</td>\n",
       "      <td>tax</td>\n",
       "      <td>2017</td>\n",
       "      <td>changes</td>\n",
       "      <td>super</td>\n",
       "      <td>east</td>\n",
       "      <td>action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>weather</td>\n",
       "      <td>driver</td>\n",
       "      <td>city</td>\n",
       "      <td>wa</td>\n",
       "      <td>review</td>\n",
       "      <td>new</td>\n",
       "      <td>climate</td>\n",
       "      <td>shows</td>\n",
       "      <td>train</td>\n",
       "      <td>jail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>victorian</td>\n",
       "      <td>five</td>\n",
       "      <td>young</td>\n",
       "      <td>michael</td>\n",
       "      <td>rise</td>\n",
       "      <td>youth</td>\n",
       "      <td>first</td>\n",
       "      <td>study</td>\n",
       "      <td>security</td>\n",
       "      <td>newcastle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>port</td>\n",
       "      <td>service</td>\n",
       "      <td>rugby</td>\n",
       "      <td>sport</td>\n",
       "      <td>media</td>\n",
       "      <td>community</td>\n",
       "      <td>laws</td>\n",
       "      <td>push</td>\n",
       "      <td>new</td>\n",
       "      <td>mark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>island</td>\n",
       "      <td>shooting</td>\n",
       "      <td>wins</td>\n",
       "      <td>regional</td>\n",
       "      <td>deal</td>\n",
       "      <td>body</td>\n",
       "      <td>make</td>\n",
       "      <td>podcast</td>\n",
       "      <td>grand</td>\n",
       "      <td>chief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>abuse</td>\n",
       "      <td>students</td>\n",
       "      <td>open</td>\n",
       "      <td>risk</td>\n",
       "      <td>housing</td>\n",
       "      <td>fire</td>\n",
       "      <td>time</td>\n",
       "      <td>art</td>\n",
       "      <td>inquest</td>\n",
       "      <td>appeal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic # 01 Topic # 02 Topic # 03 Topic # 04  Topic # 05 Topic # 06  \\\n",
       "0   queensland      rural     sydney   canberra          wa     police   \n",
       "1        court        two      world      north       calls      death   \n",
       "2        woman         90      china      perth         new        say   \n",
       "3          nsw     attack        win      coast        call    missing   \n",
       "4   indigenous      crash        cup       2015       labor   children   \n",
       "5      charged        car   business        afl     funding        nrl   \n",
       "6        child     police     market       gold          nt     darwin   \n",
       "7        power      women  australia     record     council       john   \n",
       "8      farmers       dead      final       four      hobart       west   \n",
       "9       murder     health       home  interview         qld     cattle   \n",
       "10        live  christmas     league       show       royal       road   \n",
       "11      police     killed  melbourne    cyclone     support     search   \n",
       "12         sex        nsw        hit       2016        bill       coal   \n",
       "13      school      house   turnbull       year  aboriginal      river   \n",
       "14     federal     second      first  president         tax       2017   \n",
       "15     weather     driver       city         wa      review        new   \n",
       "16   victorian       five      young    michael        rise      youth   \n",
       "17        port    service      rugby      sport       media  community   \n",
       "18      island   shooting       wins   regional        deal       body   \n",
       "19       abuse   students       open       risk     housing       fire   \n",
       "\n",
       "    Topic # 07  Topic # 08 Topic # 09 Topic # 10  \n",
       "0   australian  government      south      trump  \n",
       "1    australia        says   election   adelaide  \n",
       "2          day       found       news    seconds  \n",
       "3      country      donald   tasmania      years  \n",
       "4          one     accused       says   national  \n",
       "5         hour          us      water     family  \n",
       "6    tasmanian      people   victoria       drug  \n",
       "7         test       trial        top       near  \n",
       "8         year         new       take   hospital  \n",
       "9       budget      guilty       life       park  \n",
       "10        says         png  residents     energy  \n",
       "11      change       ahead   northern        new  \n",
       "12         new     markets                 court  \n",
       "13    violence        week       hill    million  \n",
       "14     changes       super       east     action  \n",
       "15     climate       shows      train       jail  \n",
       "16       first       study   security  newcastle  \n",
       "17        laws        push        new       mark  \n",
       "18        make     podcast      grand      chief  \n",
       "19        time         art    inquest     appeal  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lda_topics(lda, num_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# NMF\n",
    "\n",
    "For NMF, we need to obtain a design matrix. To improve results, I am going to apply TfIdf transformation to the counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the count vectorizer needs string inputs, not array, so I join them with a space.\n",
    "train_headlines_sentences = [' '.join(text) for text in train_headlines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#obtain a Counts design matrix. Because the size of the matrix will be large, we can set the max_features to 5000.\n",
    "vectorizer = CountVectorizer(analyzer='word', max_features=5000);\n",
    "x_counts = vectorizer.fit_transform(train_headlines_sentences);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set a TfIdf transformer, and transfer the counts with the model.\n",
    "transformer = TfidfTransformer(smooth_idf=False);\n",
    "x_tfidf = transformer.fit_transform(x_counts);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#normalize the TfIdf values so each row has unit length.\n",
    "xtfidf_norm = normalize(x_tfidf, norm='l1', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#obtain a NMF model.\n",
    "model = NMF(n_components=num_topics, init='nndsvd');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta=1, eta=0.1, init='nndsvd', l1_ratio=0.0, max_iter=200,\n",
       "  n_components=10, nls_max_iter=2000, random_state=None, shuffle=False,\n",
       "  solver='cd', sparseness=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the model\n",
    "model.fit(xtfidf_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nmf_topics(model, n_top_words):\n",
    "    \n",
    "    #the word ids obtained need to be reverse-mapped to the words so we can print the topic names.\n",
    "    feat_names = vectorizer.get_feature_names()\n",
    "    \n",
    "    word_dict = {};\n",
    "    for i in range(num_topics):\n",
    "        \n",
    "        #for each topic, obtain the largest values, and add the words they map to into the dictionary.\n",
    "        words_ids = model.components_[i].argsort()[:-20 - 1:-1]\n",
    "        words = [feat_names[key] for key in words_ids]\n",
    "        word_dict['Topic # ' + '{:02d}'.format(i+1)] = words;\n",
    "    \n",
    "    return pd.DataFrame(word_dict);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic # 01</th>\n",
       "      <th>Topic # 02</th>\n",
       "      <th>Topic # 03</th>\n",
       "      <th>Topic # 04</th>\n",
       "      <th>Topic # 05</th>\n",
       "      <th>Topic # 06</th>\n",
       "      <th>Topic # 07</th>\n",
       "      <th>Topic # 08</th>\n",
       "      <th>Topic # 09</th>\n",
       "      <th>Topic # 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>interview</td>\n",
       "      <td>seconds</td>\n",
       "      <td>police</td>\n",
       "      <td>new</td>\n",
       "      <td>fire</td>\n",
       "      <td>abc</td>\n",
       "      <td>rural</td>\n",
       "      <td>charged</td>\n",
       "      <td>council</td>\n",
       "      <td>court</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>michael</td>\n",
       "      <td>90</td>\n",
       "      <td>missing</td>\n",
       "      <td>zealand</td>\n",
       "      <td>house</td>\n",
       "      <td>weather</td>\n",
       "      <td>news</td>\n",
       "      <td>murder</td>\n",
       "      <td>says</td>\n",
       "      <td>accused</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>extended</td>\n",
       "      <td>business</td>\n",
       "      <td>probe</td>\n",
       "      <td>laws</td>\n",
       "      <td>crews</td>\n",
       "      <td>sport</td>\n",
       "      <td>nsw</td>\n",
       "      <td>crash</td>\n",
       "      <td>water</td>\n",
       "      <td>murder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>david</td>\n",
       "      <td>sport</td>\n",
       "      <td>search</td>\n",
       "      <td>document</td>\n",
       "      <td>threat</td>\n",
       "      <td>news</td>\n",
       "      <td>national</td>\n",
       "      <td>woman</td>\n",
       "      <td>govt</td>\n",
       "      <td>faces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>james</td>\n",
       "      <td>weather</td>\n",
       "      <td>investigate</td>\n",
       "      <td>hospital</td>\n",
       "      <td>destroys</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>qld</td>\n",
       "      <td>death</td>\n",
       "      <td>us</td>\n",
       "      <td>front</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>john</td>\n",
       "      <td>news</td>\n",
       "      <td>hunt</td>\n",
       "      <td>year</td>\n",
       "      <td>school</td>\n",
       "      <td>business</td>\n",
       "      <td>podcast</td>\n",
       "      <td>car</td>\n",
       "      <td>plan</td>\n",
       "      <td>told</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nrl</td>\n",
       "      <td>closer</td>\n",
       "      <td>death</td>\n",
       "      <td>home</td>\n",
       "      <td>home</td>\n",
       "      <td>market</td>\n",
       "      <td>reporter</td>\n",
       "      <td>stabbing</td>\n",
       "      <td>australia</td>\n",
       "      <td>charges</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ivan</td>\n",
       "      <td>confidence</td>\n",
       "      <td>car</td>\n",
       "      <td>deal</td>\n",
       "      <td>blaze</td>\n",
       "      <td>analysis</td>\n",
       "      <td>country</td>\n",
       "      <td>two</td>\n",
       "      <td>report</td>\n",
       "      <td>case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>matt</td>\n",
       "      <td>exchange</td>\n",
       "      <td>shooting</td>\n",
       "      <td>centre</td>\n",
       "      <td>suspicious</td>\n",
       "      <td>talks</td>\n",
       "      <td>nrn</td>\n",
       "      <td>assault</td>\n",
       "      <td>back</td>\n",
       "      <td>hears</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nathan</td>\n",
       "      <td>analysis</td>\n",
       "      <td>officer</td>\n",
       "      <td>york</td>\n",
       "      <td>warning</td>\n",
       "      <td>speaks</td>\n",
       "      <td>hour</td>\n",
       "      <td>sydney</td>\n",
       "      <td>closer</td>\n",
       "      <td>drug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>chris</td>\n",
       "      <td>friday</td>\n",
       "      <td>crash</td>\n",
       "      <td>president</td>\n",
       "      <td>factory</td>\n",
       "      <td>wild</td>\n",
       "      <td>health</td>\n",
       "      <td>fatal</td>\n",
       "      <td>health</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>luke</td>\n",
       "      <td>small</td>\n",
       "      <td>seek</td>\n",
       "      <td>gets</td>\n",
       "      <td>season</td>\n",
       "      <td>breakfast</td>\n",
       "      <td>sach</td>\n",
       "      <td>trial</td>\n",
       "      <td>call</td>\n",
       "      <td>sex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>andrew</td>\n",
       "      <td>wild</td>\n",
       "      <td>arrest</td>\n",
       "      <td>opens</td>\n",
       "      <td>sydney</td>\n",
       "      <td>learning</td>\n",
       "      <td>drought</td>\n",
       "      <td>killed</td>\n",
       "      <td>urged</td>\n",
       "      <td>appeal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>smith</td>\n",
       "      <td>chamber</td>\n",
       "      <td>fatal</td>\n",
       "      <td>chief</td>\n",
       "      <td>damages</td>\n",
       "      <td>friday</td>\n",
       "      <td>tasmania</td>\n",
       "      <td>attack</td>\n",
       "      <td>hospital</td>\n",
       "      <td>alleged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tim</td>\n",
       "      <td>bad</td>\n",
       "      <td>find</td>\n",
       "      <td>named</td>\n",
       "      <td>residents</td>\n",
       "      <td>report</td>\n",
       "      <td>ntch</td>\n",
       "      <td>jailed</td>\n",
       "      <td>wa</td>\n",
       "      <td>assault</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>scott</td>\n",
       "      <td>good</td>\n",
       "      <td>assault</td>\n",
       "      <td>ceo</td>\n",
       "      <td>killed</td>\n",
       "      <td>891</td>\n",
       "      <td>doctors</td>\n",
       "      <td>teen</td>\n",
       "      <td>wins</td>\n",
       "      <td>fronts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>peter</td>\n",
       "      <td>market</td>\n",
       "      <td>drug</td>\n",
       "      <td>get</td>\n",
       "      <td>control</td>\n",
       "      <td>darwin</td>\n",
       "      <td>quarter</td>\n",
       "      <td>found</td>\n",
       "      <td>australian</td>\n",
       "      <td>trial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mark</td>\n",
       "      <td>pm</td>\n",
       "      <td>found</td>\n",
       "      <td>life</td>\n",
       "      <td>destroyed</td>\n",
       "      <td>wednesday</td>\n",
       "      <td>tas</td>\n",
       "      <td>guilty</td>\n",
       "      <td>funding</td>\n",
       "      <td>child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>matthew</td>\n",
       "      <td>thursday</td>\n",
       "      <td>body</td>\n",
       "      <td>mayor</td>\n",
       "      <td>ban</td>\n",
       "      <td>radio</td>\n",
       "      <td>friday</td>\n",
       "      <td>driver</td>\n",
       "      <td>calls</td>\n",
       "      <td>stabbing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>shane</td>\n",
       "      <td>monday</td>\n",
       "      <td>station</td>\n",
       "      <td>rules</td>\n",
       "      <td>woman</td>\n",
       "      <td>thursday</td>\n",
       "      <td>monday</td>\n",
       "      <td>shooting</td>\n",
       "      <td>budget</td>\n",
       "      <td>charge</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic # 01  Topic # 02   Topic # 03 Topic # 04  Topic # 05     Topic # 06  \\\n",
       "0   interview     seconds       police        new        fire            abc   \n",
       "1     michael          90      missing    zealand       house        weather   \n",
       "2    extended    business        probe       laws       crews          sport   \n",
       "3       david       sport       search   document      threat           news   \n",
       "4       james     weather  investigate   hospital    destroys  entertainment   \n",
       "5        john        news         hunt       year      school       business   \n",
       "6         nrl      closer        death       home        home         market   \n",
       "7        ivan  confidence          car       deal       blaze       analysis   \n",
       "8        matt    exchange     shooting     centre  suspicious          talks   \n",
       "9      nathan    analysis      officer       york     warning         speaks   \n",
       "10      chris      friday        crash  president     factory           wild   \n",
       "11       luke       small         seek       gets      season      breakfast   \n",
       "12     andrew        wild       arrest      opens      sydney       learning   \n",
       "13      smith     chamber        fatal      chief     damages         friday   \n",
       "14        tim         bad         find      named   residents         report   \n",
       "15      scott        good      assault        ceo      killed            891   \n",
       "16      peter      market         drug        get     control         darwin   \n",
       "17       mark          pm        found       life   destroyed      wednesday   \n",
       "18    matthew    thursday         body      mayor         ban          radio   \n",
       "19      shane      monday      station      rules       woman       thursday   \n",
       "\n",
       "   Topic # 07 Topic # 08  Topic # 09 Topic # 10  \n",
       "0       rural    charged     council      court  \n",
       "1        news     murder        says    accused  \n",
       "2         nsw      crash       water     murder  \n",
       "3    national      woman        govt      faces  \n",
       "4         qld      death          us      front  \n",
       "5     podcast        car        plan       told  \n",
       "6    reporter   stabbing   australia    charges  \n",
       "7     country        two      report       case  \n",
       "8         nrn    assault        back      hears  \n",
       "9        hour     sydney      closer       drug  \n",
       "10     health      fatal      health       high  \n",
       "11       sach      trial        call        sex  \n",
       "12    drought     killed       urged     appeal  \n",
       "13   tasmania     attack    hospital    alleged  \n",
       "14       ntch     jailed          wa    assault  \n",
       "15    doctors       teen        wins     fronts  \n",
       "16    quarter      found  australian      trial  \n",
       "17        tas     guilty     funding      child  \n",
       "18     friday     driver       calls   stabbing  \n",
       "19     monday   shooting      budget     charge  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nmf_topics(model, 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
